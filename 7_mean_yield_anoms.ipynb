{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Rerun everything with yields created from five year rolling mean\n",
    "## Forecasting Crop Yields on a national scale (FACYnation)\n",
    "\n",
    "### by Raphael Shirley (University of Sussex)\n",
    "\n",
    "In this notebook we take the previous model and investigate increases in temperature.\n",
    "\n",
    "## Investigating impact of temperature increases\n",
    "\n",
    "In this notebook we take the two dimensional Gaussian fitted to the regional data and check for the impact of temperature increases which should depend on where current temperatures lie with respect to the peak yield response.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun model from notebook 3\n",
    "First lets generate the same set of samples from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pystan\n",
    "\n",
    "import time\n",
    "\n",
    "from numpy import exp,arange\n",
    "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show\n",
    "\n",
    "from xidplus.stan_fit import stan_utility\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the productivity trend and find a final baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_for_comp = pd.read_table('./Crop_data_files/Maize_yield_obs_timeseries.csv', sep=',')\n",
    "anoms_for_comp = pd.read_table('./Crop_data_files/Maize_median_yield_anoms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Indiana', 'Illinois', 'Ohio', 'Nebraska', 'Iowa', 'Minnesota']\n",
    "state = 'Nebraska'\n",
    "\n",
    "years = np.arange(1960, 2008)\n",
    "anoms_by_year = [anoms_for_comp[anoms_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "yields_by_year = [yields_for_comp[yields_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_mean(temp, scale=5): # Moving average by numpy convolution\n",
    "    #print(temp)\n",
    "    temp_padded = np.pad(temp, (scale//2, scale-1-scale//2), mode='edge')\n",
    "    #print(temp_padded)\n",
    "    smoothed=np.convolve(temp_padded, np.ones((scale,))/scale, mode='valid') \n",
    "    return smoothed\n",
    "\n",
    "mv = moving_mean(yields_by_year)\n",
    "print(\"Original length: {}, new length: {}\".format(len(yields_by_year), len(mv)))\n",
    "print(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    anoms_by_year = [anoms_for_comp[anoms_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    yields_by_year = [yields_for_comp[yields_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    mean_anoms_by_year = moving_mean(yields_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "for state in states:\n",
    "    anoms_by_year = [anoms_for_comp[anoms_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    yields_by_year = [yields_for_comp[yields_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    mean_anoms_by_year = yields_by_year - moving_mean(yields_by_year)\n",
    "    \n",
    "    plt.scatter(years, mean_anoms_by_year, s = 15.0, alpha=0.5, c ='g')\n",
    "    plt.scatter(years, anoms_by_year, s = 15.0, alpha=0.5, c ='b')\n",
    "    plt.scatter(years, yields_by_year, s = 15.0, alpha=0.5, c ='r')\n",
    "    \n",
    "plt.scatter([-1], [0], s = 2.0, c ='r', label = 'actual values')\n",
    "plt.scatter([-1], [0], s = 2.0, c ='b', label = '5 year median anomalies')\n",
    "plt.scatter([-1], [0], s = 2.0, c ='g', label = '5 year mean anomalies')\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('Yield [tonnes ha$^{-1}$]')\n",
    "ax.set_xlim(1960, 2007)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"./figs/yields_vs_mean_anoms_noline.png\")\n",
    "plt.savefig(\"./figs/yields_vs_mean_anoms_noline.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anoms = np.array([])\n",
    "all_yields = np.array([])\n",
    "all_years = np.array([])\n",
    "for state in states:\n",
    "    anoms_by_year = [anoms_for_comp[anoms_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    yields_by_year = [yields_for_comp[yields_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    mean_anoms_by_year = yields_by_year - moving_mean(yields_by_year)\n",
    "    all_yields = np.hstack([all_yields, yields_by_year])\n",
    "    all_anoms = np.hstack([all_anoms, mean_anoms_by_year])\n",
    "    all_years = np.hstack([all_years, years])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "import scipy\n",
    "slope, intercept, rval, pval, sterr = scipy.stats.linregress(all_years, all_yields)\n",
    "\n",
    "x = np.array([1950., 2020.])\n",
    "y = slope * x + intercept\n",
    "plt.plot(x, y, c ='r')\n",
    "   \n",
    "plt.scatter( all_years,  all_yields, s = 15.0, alpha=0.5, c ='r', label = 'Actual values')\n",
    "plt.scatter( all_years,  all_anoms, s = 15.0, alpha=0.5, c ='b', label = 'Anomalies')\n",
    "\n",
    "    \n",
    "#plt.scatter([-1], [0], s = 5.0, c ='b', label = 'anomalies')\n",
    "#plt.scatter([-1], [0], s = 5.0, c ='r', label = 'actual values')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Yield [tonnes ha$^{-1}$]')\n",
    "ax.set_xlim(1960, 2007)\n",
    "ax.set_ylim(-4, 12)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"./figs/yields_vs_mean_anoms.png\")\n",
    "plt.savefig(\"./figs/yields_vs_mean_anoms.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_anoms = yields_for_comp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anoms[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions = mean_anoms['Region']\n",
    "all_anoms = np.array([])\n",
    "all_yields = np.array([])\n",
    "all_years = np.array([])\n",
    "for m, state in enumerate(all_regions):\n",
    "    print(state)\n",
    "\n",
    "    yields_by_year = [yields_for_comp[yields_for_comp['Region'] == state][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    mean_anoms_by_year = yields_by_year - moving_mean(yields_by_year)\n",
    "    all_yields = np.hstack([all_yields, yields_by_year])\n",
    "    all_anoms = np.hstack([all_anoms, mean_anoms_by_year])\n",
    "    all_years = np.hstack([all_years, years])\n",
    "    \n",
    "    for n,year in enumerate(years):\n",
    "        mean_anoms.loc[m, str(year)] = all_anoms[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_anoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write rolling five year mean anomolies to csv for use throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_anoms.to_csv('./Crop_data_files/Maize_mean_yield_anoms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun full notebook as notebook 6 but with five year rolling mean anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted value in 2019 is {}'.format(slope * 2019 + intercept) )\n",
    "print('latest value in 2007 is {}'.format(slope * 2007 + intercept) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "months = all_months[3:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_mean_anom(table):\n",
    "    means_by_year = []\n",
    "    for year in np.arange(1980, 2008):\n",
    "        means_by_year.append(np.mean(\n",
    "            [table[str(month)][table['Unnamed: 0'] ==  year].iloc[0]  for month in months ]\n",
    "        ) )\n",
    "    return np.array(means_by_year)\n",
    "    \n",
    "precip_mean_anoms = np.array([])\n",
    "temp_mean_anoms   = np.array([])\n",
    "yields_from_1980  = np.array([])\n",
    "\n",
    "for state in states:\n",
    "    precip_month_anoms = pd.read_table(\n",
    "        'Crop_data_files/maize_met_anoms/Maize_Spring_USA_{}_precip_anom_real.csv'.format(state))\n",
    "    temp_month_anoms = pd.read_table(\n",
    "        'Crop_data_files/maize_met_anoms/Maize_Spring_USA_{}_temp_anom_real.csv'.format(state))\n",
    "\n",
    "    precip_mean_anoms = np.hstack([precip_mean_anoms,\n",
    "                                   take_mean_anom(precip_month_anoms)])\n",
    "    temp_mean_anoms = np.hstack([temp_mean_anoms,\n",
    "                                 take_mean_anom(temp_month_anoms)])\n",
    "    yields_from_1980 = np.hstack([ yields_from_1980,\n",
    "                                  ([yields_for_comp[\n",
    "                                      yields_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)\n",
    "                                  ][str(year)].iloc[0] \n",
    "                 for year in np.arange(1980, 2008)]) \n",
    "                                 ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the sources.\n",
    "fig, axis = plt.subplots()\n",
    "\n",
    "\n",
    "im = axis.scatter(temp_mean_anoms, \n",
    "                  precip_mean_anoms, \n",
    "                  c=yields_from_1980,  \n",
    "                  cmap=\"viridis\",\n",
    "                  s=50.0,\n",
    "                 alpha = 1.)#vmin=0.0, vmax=360.,\n",
    "axis.set_xlabel(\"Average monthly temperature anomaly [K]\")\n",
    "axis.set_ylabel(\"Average monthly precipitation anomaly [mm]\")\n",
    "#axis.axis('equal')\n",
    "\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# Optionally add a colorbar\n",
    "#cax, _ = mpl.colorbar.make_axes(ax)\n",
    "#cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap)\n",
    "\n",
    "\n",
    "plt.savefig('./figs/real_data_scatter.pdf', bbox_inches='tight')\n",
    "plt.savefig('./figs/real_data_scatter.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "test = np.full([10, 10], np.nan)\n",
    "\n",
    "ts = np.linspace(-2,2, 10)\n",
    "ps = np.linspace(-60,60, 10)\n",
    "\n",
    "t_width = np.absolute(ts[1] - ts[0])\n",
    "p_width = np.absolute(ps[1] - ps[0])\n",
    "\n",
    "X,Y = meshgrid(ts, ps) # grid of point\n",
    "\n",
    "def z_func(X,Y):\n",
    "    in_bin = temp_mean_anoms > (X - t_width/2)\n",
    "    in_bin = np.bitwise_and(in_bin , temp_mean_anoms < (X + t_width/2) )\n",
    "    in_bin = np.bitwise_and(in_bin , precip_mean_anoms > (Y - p_width/2) )\n",
    "    in_bin = np.bitwise_and(in_bin , precip_mean_anoms < (Y + p_width/2) )\n",
    "    yields_temp = in_bin*yields_from_1980\n",
    "    yields_temp[np.isclose(yields_temp , 0)] = np.nan\n",
    "    return np.nanmean(yields_temp)\n",
    "\n",
    "\n",
    "z_func = np.vectorize(z_func)\n",
    "#Lets use the median\n",
    "\n",
    "Z = z_func(X, Y)\n",
    "\n",
    "im = imshow(np.flip(Z, axis=0),cmap=\"viridis\", \n",
    "            extent=[ts[0],ts[-1] ,ps[0], ps[-1]],\n",
    "            aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "cbar = colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "ax.set_xlabel('Monthly mean $T_{inc}$ [K]')\n",
    "ax.set_ylabel('Monthly mean $P_{inc}$ [mm]')\n",
    "\n",
    "plt.savefig('./figs/real_data_hist.pdf', bbox_inches='tight')\n",
    "plt.savefig('./figs/real_data_hist.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for state in states:\n",
    "    precip_month_anoms = pd.read_table(\n",
    "        'Crop_data_files/maize_met_anoms/Maize_Spring_USA_{}_precip_anom_real.csv'.format(state))\n",
    "    temp_month_anoms = pd.read_table(\n",
    "        'Crop_data_files/maize_met_anoms/Maize_Spring_USA_{}_temp_anom_real.csv'.format(state))\n",
    "    \n",
    "    yields_by_year = [yields_for_comp[yields_for_comp['Region'] == 'Maize_Spring_USA_{}'.format(state)\n",
    "                                     ][str(year)].iloc[0] \n",
    "                 for year in years]\n",
    "    \n",
    "    #temp_mean =  np.nanmean(np.array(temp_month_anoms[all_months]))\n",
    "    temp_variance = np.nanstd(np.array(temp_month_anoms[all_months])) \n",
    "    #precip_mean =  np.nanmean(np.array(precip_month_anoms[all_months]))\n",
    "    precip_variance = np.nanstd(np.array(precip_month_anoms[all_months])) \n",
    "    yield_variance = np.nanstd(np.array(yields_by_year)) \n",
    "    \n",
    "    print(\"{} & {} & {} & {} \\\\\\\\ \".format(state, \n",
    "                                 #round(temp_mean, 2), \n",
    "                                 round(temp_variance, 2), \n",
    "                                 #round(precip_mean, 2),\n",
    "                                 round(precip_variance, 2),\n",
    "                                 round(yield_variance, 2)\n",
    "                                     )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_month_anoms = pd.read_table(\n",
    "        'Crop_data_files/maize_met_anoms/Maize_Spring_USA_{}_precip_anom_real.csv'.format(state))\n",
    "np.array(precip_month_anoms[all_months])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun the full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in climate temperatures\n",
    "clim_temp_maize=pd.read_table('./Crop_data_files/clim_file/temp_climatology_Maize.csv')\n",
    "clim_temp_maize.rename(columns = {'Unnamed: 0':'Crop_season_location'}, inplace = True)\n",
    "# Read in climate precipitation\n",
    "clim_precip_maize=pd.read_table('./Crop_data_files/clim_file/precip_climatology_Maize.csv')\n",
    "clim_precip_maize.rename(columns = {'Unnamed: 0':'Crop_season_location'}, inplace = True)\n",
    "# Read in Yields\n",
    "yields=pd.read_table('./Crop_data_files/Maize_mean_yield_anoms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=['Indiana','Illinois', 'Ohio','Nebraska', 'Iowa','Minnesota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in and add back mean temperature to get real temperature values\n",
    "temp_states=[]\n",
    "for i,s in enumerate(states):\n",
    "    maize_temp=pd.read_table('./Crop_data_files/maize_met_anoms/Maize_Spring_USA_'\n",
    "                             +s+'_temp_anom_real.csv')\n",
    "    maize_temp.rename(columns = {'Unnamed: 0':'Year'}, inplace = True)\n",
    "    tmp=maize_temp.iloc[:,1:].add(clim_temp_maize[\n",
    "        clim_temp_maize['Crop_season_location']== 'Maize_Spring_USA_'+states[0]\n",
    "                                                 ].iloc[0,1:,])\n",
    "    temp_states.append(tmp)\n",
    "temp_states=pd.concat(temp_states,keys=states)\n",
    "\n",
    "#Read in and add back mean precipitation to get real precipitation values\n",
    "precip_states=[]\n",
    "for i,s in enumerate(states):\n",
    "    maize_precip=pd.read_table('./Crop_data_files/maize_met_anoms/Maize_Spring_USA_'\n",
    "                               +s+'_precip_anom_real.csv')\n",
    "    maize_precip.rename(columns = {'Unnamed: 0':'Year'}, inplace = True)\n",
    "    tmp=maize_precip.iloc[:,1:].add(clim_precip_maize[\n",
    "        clim_precip_maize['Crop_season_location']== 'Maize_Spring_USA_'+states[0]\n",
    "                                                     ].iloc[0,1:,])\n",
    "    precip_states.append(tmp)\n",
    "precip_states=pd.concat(precip_states,keys=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_years=np.array(yields[yields['Region']=='Maize_Spring_USA_Indiana'].iloc[0,22:]).size\n",
    "data2={\n",
    "    'n_regions':len(states),\n",
    "    'n_years':n_years,\n",
    "    'd_temp':np.array(temp_states.iloc[:,3:9]).reshape(\n",
    "                     len(states),\n",
    "                     np.int(np.array(temp_states.iloc[:,3:9]).shape[0]/len(states)),6\n",
    "                                                      ).astype(float),\n",
    "    'd_precip':np.array(precip_states.iloc[:,3:9]).reshape(\n",
    "                     len(states),\n",
    "                     np.int(np.array(precip_states.iloc[:,3:9]).shape[0]/len(states)),6\n",
    "                                                      ).astype(float),\n",
    "    'd_yields':np.array(yields[yields[\"Region\"].isin(\n",
    "                     ['Maize_Spring_USA_'+s for s in states]\n",
    "                                                    )].iloc[:,22:]).astype(float)+9.75,\n",
    "    'n_gf':40,\n",
    "    'temp':np.arange(0,40,1),\n",
    "    'precip':np.arange(0,200,5)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gm2 = pystan.StanModel(file='./stan/2d-gaussian.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit=gm2.sampling(data=data2,chains=4,iter=1000,verbose=True,seed=1308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# carry out some diagnostic checks on fit\n",
    "\n",
    "stan_utility.check_div(fit)\n",
    "stan_utility.check_energy(fit)\n",
    "stan_utility.check_treedepth(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=fit.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,10))\n",
    "for i in range(0,2000,10):\n",
    "    plt.plot(fit.data['temp'],samples['fdy1'][i,:],alpha=0.1, c='b')\n",
    "plt.xlabel('Temperature [$^\\circ$C]')\n",
    "plt.ylabel(r'$dy$ [tonnes ha$^{-1}$]')\n",
    "\n",
    "plt.savefig('./figs/2d_Gauss_temp_post_sample_growth_curve.pdf')\n",
    "plt.savefig('./figs/2d_Gauss_temp_post_sample_growth_curve.png')\n",
    "#plt.title('Growth Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2000,10):\n",
    "    plt.plot(fit.data['precip'],samples['fdy2'][i,:],alpha=0.1, c='b')\n",
    "plt.xlabel('Precipitation [mm]')\n",
    "plt.ylabel(r'$dy$ [tonnes ha$^{-1}$]')\n",
    "plt.savefig('./figs/2d_Gauss_precip_post_sample_growth_curve.pdf')\n",
    "plt.savefig('./figs/2d_Gauss_precip_post_sample_growth_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a sample of region averaged yield anomalies for each posterior sample\n",
    "\n",
    "We have a sample from the posterior on the Gaussian parameters $\\boldsymbol \\theta_i$. For each sample, $i$, we want to compute the mean yield anomaly for all the regions combined at a given temperature increment $\\Delta T_j$ applied to every tru temperature. After this procedure we will have a sample of mean yield anomalies $Y_i_j$ for each temperature increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_anomaly(temp_6m, precip_6m, mu_t, sigma_t, mu_p, sigma_p, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-0.5 *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                             + np.square((precip_6m[month] - mu_p)/sigma_p) )\n",
    "                                      )\n",
    "    return np.sum(dy)\n",
    "\n",
    "\n",
    "def compute_mean_yield_anomaly(T_inc, data, mu_t, sigma_t, mu_p, sigma_p, norm):\n",
    "    \"\"\" Compute mean yield anomaly for a model over regions and years\n",
    "    \n",
    "    The function yield_anomaly returens the yield anomaly for a year \n",
    "    and and region. Here we loop over the regions and years to create\n",
    "    and overall mean.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    yield_anomalies = np.full((6, 35), np.nan)\n",
    "    #loop over states\n",
    "    for state in np.arange(6):\n",
    "        #loop over years\n",
    "        for year in np.arange(35):\n",
    "            temp_6m = data['d_temp'][state, year, :] + T_inc\n",
    "            precip_6m = data['d_precip'][state, year, :]\n",
    "            yield_anomalies[state, year] = yield_anomaly(temp_6m, precip_6m, mu_t, sigma_t, mu_p, sigma_p, norm)\n",
    "    \n",
    "    return np.nanmean(yield_anomalies)\n",
    "\n",
    "\n",
    "compute_mean_yield_anomaly(1., data2, 19.71, 5.23, 114.69, 62.41, [1.56])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "compute_mean_yield_anomaly(1., data2, 20., 5., 120., 65., [1.5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(200000* 14.e-3)/(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are six regions each with 35 years with six months. We want the total average for each parameter set and temperature increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_incs = np.linspace(-5, 5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((len(samples['mu_t']), len(T_incs))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_yield_samples =  np.zeros((len(samples['mu_t']), len(T_incs)))\n",
    "\n",
    "#Loop over the samples and for each parameter realisation\n",
    "#TODO: Vectorise to speed up\n",
    "\n",
    "for n in np.arange(len(samples['mu_t'])):\n",
    "    \n",
    "    mu_t    = samples['mu_t'][n]\n",
    "    sigma_t = samples['sigma_t'][n]\n",
    "    mu_p    = samples['mu_p'][n]\n",
    "    sigma_p = samples['sigma_p'][n]\n",
    "    norm    = [samples['norm'][n]]\n",
    "    for m, T_inc in enumerate(T_incs):\n",
    "        mean_yield_samples[n, m] = compute_mean_yield_anomaly(T_inc, data2, mu_t, sigma_t, mu_p, sigma_p, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_yield_samples.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means   = [np.mean(s) for s in mean_yield_samples.T]\n",
    "sample_medians = [np.median(s) for s in mean_yield_samples.T]\n",
    "sample_25      = [np.percentile(s, 25.) for s in mean_yield_samples.T]\n",
    "sample_75      = [np.percentile(s, 75.)  for s in mean_yield_samples.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(T_incs, sample_means, label='means')\n",
    "#plt.plot(T_incs, sample_medians, label='medians')\n",
    "#plt.plot(T_incs, sample_25, label='25th percentile')\n",
    "#plt.plot(T_incs, sample_75, label='75th percentile')\n",
    "plt.fill_between(T_incs, sample_25, sample_75, label='75th - 25th percentile', alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel('T_inc (K)')\n",
    "plt.ylabel('Yield [tonnes ha$^{-1}$]')\n",
    "plt.savefig('./figs/temperature_impact.pdf')\n",
    "plt.savefig('./figs/temperature_impact.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_yield_samples.T[33], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_yield_samples.T[0], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly shows that the model predicts reductions in yields as a consequence of raising temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a two dimensional plot of the function on one posterior\n",
    "\n",
    "We want to see how the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior sample\n",
    "#                    mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "#mu_t               19.71    0.02   0.68  18.17  19.29  19.77  20.19  20.87   1205    1.0\n",
    "#sigma_t             5.23    0.02   0.58   4.26    4.8   5.17    5.6   6.49    795    1.0\n",
    "#mu_p              114.69    0.11   4.26 106.07 111.81 114.87 117.65 122.71   1571    1.0\n",
    "#sigma_p            62.41    0.07   2.76  57.16  60.51  62.41  64.24   67.9   1633    1.0\n",
    "#norm                1.56  2.3e-3   0.07   1.43   1.51   1.56    1.6    1.7    862    1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "t1, t2 = 5., 35.\n",
    "p1, p2 = 0., 250.\n",
    "x = arange(t1,t2,.1)\n",
    "y = arange(p1,p2,1.)\n",
    "X,Y = meshgrid(x, y) # grid of point\n",
    "def yield_equal(temp, precip, mu_t, sigma_t, mu_p, sigma_p, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    temp_6m = np.full(6, temp)\n",
    "    precip_6m = np.full(6, precip)\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-0.5 *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                             + np.square((precip_6m[month] - mu_p)/sigma_p) )\n",
    "                                      )\n",
    "    return np.sum(dy)\n",
    "def z_func(X,Y):\n",
    "    return yield_equal(X, Y, 19.77, 5.17, 114.87, 62.41, [1.56])\n",
    "z_func = np.vectorize(z_func)\n",
    "#Lets use the median\n",
    "\n",
    "Z = z_func(X, Y) # evaluation of the function on the grid\n",
    "\n",
    "im = imshow(Z,cmap=\"viridis\", extent=[t1,t2,p1,p2], aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "ax.set_xlabel('T [$^{\\circ}$C]')\n",
    "ax.set_ylabel('Monthly precipitation (mm)')\n",
    "\n",
    "plt.savefig('./figs/2d_yield_response.pdf')\n",
    "plt.savefig('./figs/2d_yield_response.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "t1, t2 = 5., 35.\n",
    "p1, p2 = 0., 250.\n",
    "x = arange(t1,t2,.1)\n",
    "y = arange(p1,p2,1.)\n",
    "X,Y = meshgrid(x, y) # grid of point\n",
    "def yield_equal(temp, precip, mu_t, sigma_t, mu_p, sigma_p, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    temp_6m = np.full(6, temp)\n",
    "    precip_6m = np.full(6, precip)\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-0.5 *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                             + np.square((precip_6m[month] - mu_p)/sigma_p) )\n",
    "                                      )\n",
    "    return np.sum(dy)\n",
    "def z_func(X,Y):\n",
    "    return yield_equal(X, Y, 19.77, 5.17, 114.87, 62.41, [1.56])\n",
    "z_func = np.vectorize(z_func)\n",
    "#Lets use the median\n",
    "\n",
    "Z = z_func(X, Y) # evaluation of the function on the grid\n",
    "\n",
    "im = imshow(Z,cmap=\"viridis\", extent=[t1,t2,p1,p2], aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "CS = ax.contour(X, Y, Z)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "\n",
    "ax.set_xlabel('T [$^{\\circ}$C]')\n",
    "ax.set_ylabel('Monthly precipitation (mm)')\n",
    "\n",
    "plt.savefig('./figs/2d_yield_response_contours.pdf')\n",
    "plt.savefig('./figs/2d_yield_response_contours.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include correlation\n",
    "\n",
    "We originally ran a zero correlated gaussian, now let's incldue correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm3 = pystan.StanModel(file='./stan/2d-gaussian_with_correlation.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2=gm3.sampling(data=data2,chains=4,iter=1000,verbose=True,seed=1308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry out some diagnostic checks on fit\n",
    "\n",
    "stan_utility.check_div(fit2)\n",
    "stan_utility.check_energy(fit2)\n",
    "stan_utility.check_treedepth(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2=fit2.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,10))\n",
    "for i in range(0,2000,10):\n",
    "    plt.plot(fit2.data['temp'],samples['fdy1'][i,:],alpha=0.1, c='b')\n",
    "plt.xlabel('Temperature [$^{\\circ}$C]')\n",
    "plt.ylabel(r'$dy$')\n",
    "#plt.title('Growth Curve')\n",
    "plt.savefig('./figs/growth_curve.pdf')\n",
    "plt.savefig('./figs/growth_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_anomaly2(temp_6m, precip_6m, mu_t, sigma_t, mu_p, sigma_p, rho, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-(1/(2 - 2*rho**2)) *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                                           + np.square((precip_6m[month] - mu_p)/sigma_p) \n",
    "                                                           - (2*rho*(temp_6m[month]    - mu_t)\n",
    "                                                                   *(precip_6m[month] - mu_p)\n",
    "                                                             )\n",
    "                                                              /(sigma_t*sigma_p)\n",
    "                                                           )\n",
    "                                      )\n",
    "                                      \n",
    "    return np.sum(dy)\n",
    "\n",
    "\n",
    "def compute_mean_yield_anomaly2(T_inc, data, mu_t, sigma_t, mu_p, sigma_p, rho, norm):\n",
    "    \"\"\" Compute mean yield anomaly for a model over regions and years\n",
    "    \n",
    "    The function yield_anomaly returens the yield anomaly for a year \n",
    "    and and region. Here we loop over the regions and years to create\n",
    "    and overall mean.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    yield_anomalies = np.full((6, 35), np.nan)\n",
    "    #loop over states\n",
    "    for state in np.arange(6):\n",
    "        #loop over years\n",
    "        for year in np.arange(35):\n",
    "            temp_6m = data['d_temp'][state, year, :] + T_inc\n",
    "            precip_6m = data['d_precip'][state, year, :]\n",
    "            yield_anomalies[state, year] = yield_anomaly2(temp_6m, \n",
    "                                                         precip_6m, \n",
    "                                                         mu_t, \n",
    "                                                         sigma_t, \n",
    "                                                         mu_p, \n",
    "                                                         sigma_p,\n",
    "                                                         rho, \n",
    "                                                         norm)\n",
    "    \n",
    "    return np.nanmean(yield_anomalies)\n",
    "\n",
    "\n",
    "compute_mean_yield_anomaly2(1., data2, 19.71, 5.23, 114.69, 62.41, 0.0, [1.56])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Loop over the samples and for each parameter realisation\n",
    "\n",
    "T_incs_corr = np.linspace(-5, 5, 50)\n",
    "mean_yield_samples2 =  np.full((len(samples2['mu_t']), len(T_incs_corr)), np.nan)\n",
    "\n",
    "for n in np.arange(len(samples2['mu_t'])):\n",
    "    if n % 100 == 0:\n",
    "        print(\"{} out of {}\".format(n, len(samples2['mu_t'])))\n",
    "    mu_t    = samples2['mu_t'][n]\n",
    "    sigma_t = samples2['sigma_t'][n]\n",
    "    mu_p    = samples2['mu_p'][n]\n",
    "    sigma_p = samples2['sigma_p'][n]\n",
    "    rho = samples2['rho'][n]\n",
    "    norm    = [samples2['norm'][n]]\n",
    "    for m, T_inc in enumerate(T_incs_corr):\n",
    "        mean_yield_samples2[n, m] = compute_mean_yield_anomaly2(T_inc, data2, mu_t, sigma_t, mu_p, sigma_p, rho, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_yield_samples2', mean_yield_samples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2_means   = [np.mean(s) for s in mean_yield_samples2.T]\n",
    "sample2_medians = [np.median(s) for s in mean_yield_samples2.T]\n",
    "sample2_25      = [np.percentile(s, 25.) for s in mean_yield_samples2.T]\n",
    "sample2_75      = [np.percentile(s, 75.)  for s in mean_yield_samples2.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(T_incs_corr, sample2_means, label='means')\n",
    "#plt.plot(T_incs, sample_medians, label='medians')\n",
    "#plt.plot(T_incs, sample_25, label='25th percentile')\n",
    "#plt.plot(T_incs, sample_75, label='75th percentile')\n",
    "plt.fill_between(T_incs_corr, sample2_25, sample2_75, label='75th - 25th percentile', alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel('T$_{{inc}}$ (K)')\n",
    "plt.ylabel('Yield [tonnes ha$^{-1}$]')\n",
    "plt.savefig('./figs/temperature_impact2_m5p5.pdf')\n",
    "plt.savefig('./figs/temperature_impact2_m5p5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                    mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
    "#mu_t               19.67    0.02   0.72  18.09  19.24  19.74  20.18  20.93   1036    1.0\n",
    "#sigma_t             5.23    0.02   0.57   4.32   4.83   5.17   5.57   6.53    797    1.0\n",
    "#mu_p              115.07    0.11   4.12 106.99 112.34 115.12 117.78 123.13   1443    1.0\n",
    "#sigma_p            62.62    0.08   2.82  57.36  60.63  62.57   64.5  68.19   1358    1.0\n",
    "#rho                -0.02  2.0e-3   0.08  -0.17  -0.07  -0.02   0.03   0.13   1433    1.0\n",
    "#norm                1.56  2.1e-3   0.07   1.44   1.51   1.56    1.6   1.69    973    1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "t1, t2 = 5., 35.\n",
    "p1, p2 = 0., 250.\n",
    "x = np.linspace(t1,t2,100.)\n",
    "y = np.linspace(p1,p2,100.)\n",
    "X,Y = meshgrid(x, y) # grid of point\n",
    "def yield_equal2(temp, precip, mu_t, sigma_t, mu_p, sigma_p, rho, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    temp_6m = np.full(6, temp)\n",
    "    precip_6m = np.full(6, precip)\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-(1/(2 - 2*rho**2)) *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                                           + np.square((precip_6m[month] - mu_p)/sigma_p) \n",
    "                                                           - (2*rho*(temp_6m[month]    - mu_t)\n",
    "                                                                   *(precip_6m[month] - mu_p)\n",
    "                                                             )\n",
    "                                                              /(sigma_t*sigma_p)\n",
    "                                                           )\n",
    "                                      )\n",
    "    return np.sum(dy)\n",
    "def z_func(X,Y):\n",
    "    return yield_equal2(X, Y, 19.74, 5.17, 115.12, 62.57, -0.02, [1.56])\n",
    "z_func = np.vectorize(z_func)\n",
    "#Lets use the median\n",
    "\n",
    "Z = z_func(X, Y) # evaluation of the function on the grid\n",
    "\n",
    "im = ax.imshow(np.flip(Z, axis=0),cmap=\"viridis\", extent=[t1,t2,p1,p2], aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "ax.set_xlabel('T (Celsius)')\n",
    "ax.set_ylabel('Monthly precipitation (mm)')\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('./figs/2d_2.pdf')\n",
    "plt.savefig('./figs/2d_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "t1, t2 = 5., 35.\n",
    "p1, p2 = 0., 250.\n",
    "x = np.linspace(t1,t2,100.)\n",
    "y = np.linspace(p1,p2,100.)\n",
    "X,Y = meshgrid(x, y) # grid of point\n",
    "def yield_equal2(temp, precip, mu_t, sigma_t, mu_p, sigma_p, rho, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    temp_6m = np.full(6, temp)\n",
    "    precip_6m = np.full(6, precip)\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-(1/(2 - 2*rho**2)) *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                                           + np.square((precip_6m[month] - mu_p)/sigma_p) \n",
    "                                                           - (2*rho*(temp_6m[month]    - mu_t)\n",
    "                                                                   *(precip_6m[month] - mu_p)\n",
    "                                                             )\n",
    "                                                              /(sigma_t*sigma_p)\n",
    "                                                           )\n",
    "                                      )\n",
    "    return np.sum(dy)\n",
    "def z_func(X,Y):\n",
    "    return yield_equal2(X, Y, 19.74, 5.17, 115.12, 62.57, -0.02, [1.56])\n",
    "z_func = np.vectorize(z_func)\n",
    "#Lets use the median\n",
    "\n",
    "Z = z_func(X, Y) # evaluation of the function on the grid\n",
    "\n",
    "im = ax.imshow(np.flip(Z, axis=0),cmap=\"viridis\", extent=[t1,t2,p1,p2], aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "ax.set_xlabel('T (Celsius)')\n",
    "ax.set_ylabel('Monthly precipitation (mm)')\n",
    "\n",
    "CS = ax.contour(X, Y, Z, 3, colors='w')\n",
    "ax.clabel(CS, inline=1, fmt='%1.1f', fontsize=10)\n",
    "\n",
    "plt.savefig('./figs/2d_2_contour.pdf')\n",
    "plt.savefig('./figs/2d_2_contour.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['d_precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets plot a response in temperature and precipitation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_incs_2 = np.linspace(-10, 10, 50)\n",
    "P_incs_2 = np.linspace(-100, 100, 50)\n",
    "T_P_grid = np.meshgrid(T_incs_2, P_incs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_anomaly2(temp_6m, precip_6m, mu_t, sigma_t, mu_p, sigma_p, rho, norm):\n",
    "    \"\"\"Take six months of T and P and return yield for given params.\n",
    "    \n",
    "    This should be identical to the function in the STAN model\n",
    "    \"\"\"\n",
    "    if len(norm) == 1:\n",
    "        norm = norm * np.ones(6)\n",
    "    dy = np.zeros(6)\n",
    "    for month in np.arange(6):\n",
    "        dy[month] = norm[month]*np.exp(-(1/(2 - 2*rho*2)) *( np.square((temp_6m[month]    - mu_t)/sigma_t) \n",
    "                                                           + np.square((precip_6m[month] - mu_p)/sigma_p) \n",
    "                                                           - (2*rho*(temp_6m[month]    - mu_t)\n",
    "                                                                   *(precip_6m[month] - mu_p)\n",
    "                                                             )\n",
    "                                                              /(sigma_t*sigma_p)\n",
    "                                                           )\n",
    "                                      )\n",
    "                                      \n",
    "    return np.sum(dy)\n",
    "\n",
    "def compute_mean_yield_anomaly3(T_inc, P_inc, data, mu_t, sigma_t, mu_p, sigma_p, rho, norm):\n",
    "    \"\"\" Compute mean yield anomaly for a model over regions and years\n",
    "    \n",
    "    The function yield_anomaly returens the yield anomaly for a year \n",
    "    and and region. Here we loop over the regions and years to create\n",
    "    and overall mean.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    yield_anomalies = np.full((6, 35), np.nan)\n",
    "    #loop over states\n",
    "    for state in np.arange(6):\n",
    "        #loop over years\n",
    "        for year in np.arange(35):\n",
    "            temp_6m = data['d_temp'][state, year, :] + T_inc\n",
    "            precip_6m = data['d_precip'][state, year, :] + P_inc\n",
    "            yield_anomalies[state, year] = yield_anomaly2(temp_6m, \n",
    "                                                         precip_6m, \n",
    "                                                         mu_t, \n",
    "                                                         sigma_t, \n",
    "                                                         mu_p, \n",
    "                                                         sigma_p,\n",
    "                                                         rho, \n",
    "                                                         norm)\n",
    "    \n",
    "    return np.nanmean(yield_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_100 = np.random.choice([0,1], \n",
    "                            size=len(samples2['mu_t']), \n",
    "                            p=(1-100/len(samples2['mu_t']), 100/len(samples2['mu_t'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_yield_anom = np.full((len(T_incs_2), len(P_incs_2)), np.nan)\n",
    "\n",
    "print(\"Starting at {}\".format(time.time()))\n",
    "for n, t in enumerate(T_incs_2):\n",
    "    print(\"{} out of {}\".format(n, len(T_incs_2)))\n",
    "    for m, p in enumerate(P_incs_2):\n",
    "        mean_yield_samples = np.full(len(samples2['mu_t']), np.nan)\n",
    "        for k in np.arange(len(samples2['mu_t'])):\n",
    "            if not take_100[k]:\n",
    "                continue\n",
    "            \n",
    "            #print('k = {}'.format(k))\n",
    "            mu_t    = samples2['mu_t'][k]\n",
    "            sigma_t = samples2['sigma_t'][k]\n",
    "            mu_p    = samples2['mu_p'][k]\n",
    "            sigma_p = samples2['sigma_p'][k]\n",
    "            rho = samples2['rho'][k]\n",
    "            norm    = [samples2['norm'][k]]\n",
    "\n",
    "            mean_yield_samples[k] = compute_mean_yield_anomaly3(t, p, data2, mu_t, sigma_t, mu_p, sigma_p, rho, norm)\n",
    "        \n",
    "        mean_yield_anom[n, m] = np.nanmean(mean_yield_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_yield_anom', mean_yield_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "im = imshow(np.flip(mean_yield_anom.T, axis=0),cmap=\"viridis\", \n",
    "            extent=[T_incs_2[0],T_incs_2[-1], P_incs_2[0], P_incs_2[-1]], \n",
    "            aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "ax.set_xlabel('$T_{inc}$ [K]')\n",
    "ax.set_ylabel('$P_{inc}$ [mm]')\n",
    "\n",
    "plt.savefig('./figs/temp_precip_impact.pdf')\n",
    "plt.savefig('./figs/temp_precip_impact.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(mean_yield_anom.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_yield_anom.T[int(len(T_incs_2)/2), int(len(P_incs_2)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9 * mean_yield_anom.T[int(len(T_incs_2)/2), int(len(P_incs_2)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "im = imshow(np.flip(mean_yield_anom.T, axis=0),cmap=\"viridis\", \n",
    "            extent=[T_incs_2[0],T_incs_2[-1], P_incs_2[0], P_incs_2[-1]], \n",
    "            aspect=\"auto\") # drawing the function\n",
    "# adding the Contour lines with labels\n",
    "#cset = contour(Z,arange(-1,1.5,0.2),linewidths=2,cmap=cm.Set2)\n",
    "#clabel(cset,inline=True,fmt='%1.1f',fontsize=10)\n",
    "cbar = fig.colorbar(im) # adding the colobar on the right\n",
    "cbar.set_label('Yield [tonnes ha$^{-1}$]')\n",
    "# latex fashion title\n",
    "#title('$z=(1-x^2+y^3) e^{-(x^2+y^2)/2}$')\n",
    "\n",
    "ax.set_xlabel('$T_{inc}$ [K]')\n",
    "ax.set_ylabel('$P_{inc}$ [mm]')\n",
    "\n",
    "CS = ax.contour(T_incs_2, P_incs_2, mean_yield_anom.T, [4., \n",
    "               6., \n",
    "               8., \n",
    "               0.9 * mean_yield_anom.T[int(len(T_incs_2)/2), int(len(P_incs_2)/2)]\n",
    "              ], colors='w')\n",
    "\n",
    "fmt = {}\n",
    "strs = ['4', '6', '8', '-10% (8.8)']\n",
    "for l, s in zip(CS.levels, strs):\n",
    "    fmt[l] = s\n",
    "ax.clabel(CS, \n",
    "          inline=1, \n",
    "          fmt=fmt, \n",
    "          fontsize=10)\n",
    "\n",
    "plt.savefig('./figs/temp_precip_impact_contour.pdf')\n",
    "plt.savefig('./figs/temp_precip_impact_contour.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(np.random.multivariate_normal(np.array([20,5]),np.array([[5.0,0.0],[0.0,1.0]]),2000),\n",
    "                columns=['$\\mu_T$','$\\sigma_T$'])\n",
    "g=sns.PairGrid(data=df,size=2.5,diag_sharey=False)\n",
    "g.map_diag(plt.hist,color='Red',alpha=0.5)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Reds\",alpha=0.8,n_levels=10,normed=True, shade=True,shade_lowest=False)\n",
    "df=pd.DataFrame(np.vstack((samples['mu_t'],samples['sigma_t'])).T,columns=['$\\mu_T$','$\\sigma_T$'])\n",
    "g.data=df\n",
    "g.map_diag(plt.hist,color='Blue',alpha=0.5)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues\",alpha=0.8,n_levels=10,normed=True, shade=True,shade_lowest=False)\n",
    "\n",
    "g.axes[0,1].set_axis_off()\n",
    "\n",
    "#fig = g.get_figure()\n",
    "plt.savefig(\"./figs/2d_Gauss_prior_vs_post_temp_mean_vs_sigma.png\")\n",
    "plt.savefig(\"./figs/2d_Gauss_prior_vs_post_temp_mean_vs_sigma.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(np.random.multivariate_normal(np.array([100,25]),np.array([[25.0,0.0],[0.0,5.0]]),2000),\n",
    "                columns=['$\\mu_p$','$\\sigma_p$'])\n",
    "g=sns.PairGrid(data=df,size=2.5,diag_sharey=False)\n",
    "g.map_diag(plt.hist,color='Red',alpha=0.5)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Reds\",alpha=0.8,n_levels=10,normed=True, shade=True,shade_lowest=False)\n",
    "df=pd.DataFrame(np.vstack((samples['mu_p'],samples['sigma_p'])).T,columns=['$\\mu_p$','$\\sigma_p$'])\n",
    "\n",
    "g.data=df\n",
    "g.map_diag(plt.hist,color='Blue',alpha=0.5)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues\",alpha=0.8,n_levels=10,normed=True, shade=True,shade_lowest=False)\n",
    "\n",
    "g.axes[0,1].set_axis_off()\n",
    "\n",
    "#fig = g.get_figure()\n",
    "plt.savefig(\"./figs/2d_Gauss_prior_vs_post_precip_mean_vs_sigma.png\")\n",
    "plt.savefig(\"./figs/2d_Gauss_prior_vs_post_precip_mean_vs_sigma.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayesian_Pval(yields,pred_yields):\n",
    "    import scipy.stats as st\n",
    "    Pvals=np.empty_like(yields)\n",
    "    n_reg,n_years=yields.shape\n",
    "    for r in range(0,n_reg):\n",
    "        for y in range(0,n_years):\n",
    "            ind=pred_yields[:,r,y]<yields[r,y]\n",
    "            Pvals[r,y]=st.norm.ppf(ind.sum()/pred_yields[:,r,y].size)\n",
    "    return Pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pvals=Bayesian_Pval(fit2.data['d_yields'],samples2['pred_yields'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,5))\n",
    "for s in range(0,len(states)):\n",
    "    plt.plot(Pvals[s,:],label=states[s])\n",
    "plt.xticks(5*np.arange(len(np.arange(1980,2015, 5))),np.arange(1980,2015, 5),rotation=90);\n",
    "plt.legend()\n",
    "plt.ylabel('P value')\n",
    "\n",
    "plt.savefig(\"./figs/pvalues_all.png\".format(states[s]))\n",
    "plt.savefig(\"./figs/pvalues_all.pdf\".format(states[s]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (herschelhelp_internal)",
   "language": "python",
   "name": "helpint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
